{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from osgeo import gdal\n",
    "from time import perf_counter\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, jaccard_score\n",
    "import torchnet as tnt\n",
    "\n",
    "from distutils.dir_util import copy_tree\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import notebook as tqdm\n",
    "\n",
    "from model_definitions import SpectroSpatialNet\n",
    "import image_preprocessing\n",
    "import inference_utils\n",
    "\n",
    "# GLOBAL SETTINGS\n",
    "PlotSize = 12                                     # Size of plots\n",
    "matplotlib.rcParams['figure.figsize'] = [PlotSize*2, PlotSize]  \n",
    "CMAP = matplotlib.colors.ListedColormap(['black', 'white', 'orange'])               # Color mapping \n",
    "np.set_printoptions(precision=2, suppress=True)  # Array print precision\n",
    "\n",
    "# PATHS TO TRAINING DATA\n",
    "trainingdata_path = r'C:\\Users\\dd\\Documents\\NATUR_CUNI\\additional_projects\\prace\\ETRAINEE\\data\\LH_202008_54pasem_9cm.tif'\n",
    "referencedata_path = r'C:\\Users\\dd\\Documents\\NATUR_CUNI\\additional_projects\\prace\\ETRAINEE\\data\\LH_trenovaci_2019a2020_rasterized.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_raster = image_preprocessing.read_gdal(trainingdata_path, referencedata_path)\n",
    "print(f'Tiled imagery shape {loaded_raster[\"imagery\"].shape}')\n",
    "print(f'Tiled reference shape {loaded_raster[\"reference\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_shape = (256, 256)\n",
    "overlap = 128\n",
    "offset = (0, 0)\n",
    "\n",
    "dataset_tiles = image_preprocessing.tile_training(loaded_raster, tile_shape, overlap, offset)\n",
    "print(f'Tiled imagery shape {dataset_tiles[\"imagery\"].shape}')\n",
    "print(f'Tiled reference shape {dataset_tiles[\"reference\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tiles = image_preprocessing.filter_useful_tiles(dataset_tiles, nodata_vals=[65535], is_training=True)\n",
    "print(f'Filtered imagery shape {filtered_tiles[\"imagery\"].shape}')\n",
    "print(f'Filtered reference shape {filtered_tiles[\"reference\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_tiles, unique, counts = image_preprocessing.normalize_tiles_3d(filtered_tiles, nodata_vals=[65535], is_training=True)\n",
    "print(f'Preprocessed imagery shape {preprocessed_tiles[\"imagery\"].shape}')\n",
    "print(f'Preprocessed reference shape {preprocessed_tiles[\"reference\"].shape}')\n",
    "\n",
    "dataset = tnt.dataset.TensorDataset([preprocessed_tiles['imagery'], preprocessed_tiles['reference']])\n",
    "print(dataset)\n",
    "\n",
    "print(f'Class labels: \\n{unique}\\n')\n",
    "print(f'Number of pixels in a class: \\n{counts}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(obs, g_t):\n",
    "    \"\"\"the data augmentation function, introduces random noise and rotation\"\"\"\n",
    "    sigma, clip= 0.01, 0.03 \n",
    "    #Hint: use np.clip to clip and np.random.randn to generate gaussian noise\n",
    "    obs = obs + np.clip(sigma*np.random.randn(), -clip, clip).astype(np.float32).copy()\n",
    "\n",
    "    #random rotation 0 90 180 270 degree\n",
    "    n_turn = np.random.randint(4) #number of 90 degree turns, random int between 0 and 3\n",
    "    obs = np.rot90(obs, n_turn, axes=(2,3)).copy()\n",
    "    g_t = np.rot90(g_t, n_turn, axes=(1,2)).copy()\n",
    "\n",
    "    obs = torch.from_numpy(obs)\n",
    "    g_t = torch.from_numpy(g_t)\n",
    "    \n",
    "    return obs, g_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, args):\n",
    "    \"\"\"train for one epoch\"\"\"\n",
    "    model.train() #switch the model in training mode\n",
    "  \n",
    "    #the loader function will take care of the batching\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=args['batch_size'], sampler=args['train_subsampler'])\n",
    "    loader = tqdm.tqdm(loader, ncols=500)\n",
    "  \n",
    "    #will keep track of the loss\n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    for index, (tiles, gt) in enumerate(loader):\n",
    "    \n",
    "        optimizer.zero_grad() #put gradient to zero\n",
    "\n",
    "        #tiles, gt = augment(tiles, gt)\n",
    "\n",
    "        pred = model(tiles.cuda()) #compute the prediction\n",
    "\n",
    "        loss = nn.functional.cross_entropy(pred.cpu(),gt, weight=args['class_weights'])\n",
    "        loss.backward() #compute gradients\n",
    "\n",
    "        for p in model.parameters(): #we clip the gradient at norm 1\n",
    "            p.grad.data.clamp_(-1, 1) #this helps learning faster\n",
    "\n",
    "        optimizer.step() #one SGD step\n",
    "        loss_meter.add(loss.item())\n",
    "        \n",
    "    return loss_meter.value()[0]\n",
    "\n",
    "def eval(model, sampler):\n",
    "    \"\"\"eval on test/validation set\"\"\"\n",
    "  \n",
    "    model.eval() #switch in eval mode\n",
    "  \n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=1, sampler=sampler)\n",
    "    loader = tqdm.tqdm(loader, ncols=500)\n",
    "  \n",
    "    loss_meter = tnt.meter.AverageValueMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for index, (tiles, gt) in enumerate(loader):\n",
    "            pred = model(tiles.cuda())\n",
    "            loss = nn.functional.cross_entropy(pred.cpu(), gt)\n",
    "            loss_meter.add(loss.item())\n",
    "\n",
    "    return loss_meter.value()[0]\n",
    "\n",
    "\n",
    "def train_full(args):\n",
    "    \"\"\"The full training loop\"\"\"\n",
    "\n",
    "    #initialize the model\n",
    "    model = SpectroSpatialNet(args)\n",
    "\n",
    "    print(f'Total number of parameters: {sum([p.numel() for p in model.parameters()])}')\n",
    "  \n",
    "    #define the Adam optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=args['scheduler_milestones'],\n",
    "                                               gamma=args['scheduler_gamma'])\n",
    "  \n",
    "    train_loss = np.empty(args['n_epoch'])\n",
    "    test_epochs = []\n",
    "    test_loss = []\n",
    "\n",
    "    for i_epoch in range(args['n_epoch']):\n",
    "        #train one epoch\n",
    "        print(f'Epoch #{str(i_epoch+1)}')\n",
    "        train_loss[i_epoch] = train(model, optimizer, args)\n",
    "        scheduler.step()\n",
    "\n",
    "        # Periodic testing on the validation set\n",
    "        if (i_epoch == args['n_epoch'] - 1) or ((i_epoch + 1) % args['n_epoch_test'] == 0):\n",
    "            print('Evaluation')\n",
    "            loss_test = eval(model, args['test_subsampler'])\n",
    "            test_epochs.append(i_epoch + 1)\n",
    "            test_loss.append(loss_test)\n",
    "            \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1,1,1,ylim=(0,5), xlabel='Epoch #', ylabel='Loss')\n",
    "    plt.plot([i+1 for i in range(args['n_epoch'])], train_loss, label='Training loss')\n",
    "    plt.plot(test_epochs, test_loss, label='Validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(train_loss)\n",
    "    print(test_loss)\n",
    "    args['loss_test'] = test_loss[-1]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a 3D network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = { #Dict to store all model parameters\n",
    "    'n_channel': 1,\n",
    "    'cuda': True,\n",
    "    'n_class': len(unique),\n",
    "    'size_e': np.divide([64,64,128,128,256,256,512,512,1024,1024],        32).astype(np.int32),\n",
    "    'size_d': np.divide(np.multiply([1024,512,512,512,256,256,256,128,128,128,64,64], 3), 32).astype(np.int32),\n",
    "    \n",
    "    'crossval_nfolds': 3,\n",
    "    'n_epoch_test': 2,          #periodicity of evaluation on test set\n",
    "    'scheduler_milestones': [60,80,90],\n",
    "    'scheduler_gamma': 0.3,\n",
    "    'class_weights': torch.tensor([0.0, 0.1966495481867119, 0.3430579108649065, 0.03228185060941156, 0.16631530937067654, 0.14084359532291527, 0.02901643207368558, 0.012932577826270997, 0.021546657524297137, 0.057356118221124304]),\n",
    "\n",
    "    'n_epoch': 5,\n",
    "    'lr': 5e-6,\n",
    "    'batch_size': 4,\n",
    "}\n",
    "model_save_folder = r'C:\\Users\\dd\\Documents\\NATUR_CUNI\\additional_projects\\prace\\ETRAINEE\\data\\models'\n",
    "print(f'''Number of models to be trained:\n",
    "    {args['crossval_nfolds']}\n",
    "Number of spectral channels:\n",
    "    {args['n_channel']}\n",
    "Initial learning rate:\n",
    "    {args['lr']}\n",
    "Batch size:\n",
    "    {args['batch_size']}\n",
    "Number of training epochs:\n",
    "    {args['n_epoch']}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Training a 3D network\n",
    "kfold = KFold(n_splits = args['crossval_nfolds'], shuffle=True)\n",
    "trained_models = []\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    print(f'Training starts for model number {str(fold+1)}')\n",
    "    \n",
    "    a = perf_counter()\n",
    "    args['train_subsampler'] = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    args['test_subsampler'] = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    trained_models.append((train_full(args), args['loss_test']))\n",
    "    \n",
    "    state_dict_path = os.path.join(model_save_folder, f'fold_{str(fold)}.pt')\n",
    "    torch.save(trained_models[fold][0].state_dict(), state_dict_path)\n",
    "    print(f'Model saved to: {state_dict_path}')\n",
    "    print(f'Training finished in {str(perf_counter()-a)}s')\n",
    "    print('\\n\\n')\n",
    "\n",
    "print(f'Resulting loss for individual folds: \\n{[i for _, i in trained_models]}')\n",
    "print(f'Mean loss across all folds: \\n{np.mean([i for _, i in trained_models])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and reusing a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the state_dictionary\n",
    "state_dict_path = r'C:\\Users\\dd\\Documents\\NATUR_CUNI\\additional_projects\\prace\\ETRAINEE\\data\\models\\fold_2.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a model to state_dict_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save a trained model state_dictionary\n",
    "torch.save(trained_model.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reuse a model at state_dict_path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters for model definition\n",
    "\n",
    "args = {} #stores the parameters\n",
    "args['n_class'] = 10\n",
    "args['n_channel'] = 1\n",
    "args['size_e'] =  np.divide([64,64,128,128,256,256,512,512,1024,1024],        32).astype(np.int32)\n",
    "args['size_d'] = np.divide(np.multiply([1024,512,512,512,256,256,256,128,128,128,64,64], 3), 32).astype(np.int32)\n",
    "args['cuda'] = True\n",
    "\n",
    "\n",
    "# Load a trained model state_dictionary\n",
    "#state_dict_path = 'd:/studenti/JD/ETRAINEE/models/fold_0.pt'\n",
    "model = SpectroSpatialNet(args)\n",
    "#state_dict_path = 'D:/Studenti/JD/Jeseniky_2020/models/KrakonosNet_jes_1e-3_200epochs.pt'\n",
    "#model = KrakonosNet(args['n_channel'], args['size_e'], args['size_d'], args['n_class'], args['cuda'])\n",
    "model.load_state_dict(torch.load(state_dict_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export results\n",
    "Results are not georeferenced â€“ use ArcPy_georeference_results.py for georeferencing and combining into a single raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = r'C:\\Users\\dd\\Documents\\NATUR_CUNI\\additional_projects\\prace\\ETRAINEE\\data\\LH_202008_54pasem_9cm.tif'\n",
    "tile_shape = (256, 256)\n",
    "overlap = 128\n",
    "offset_topleft = (0, 0)\n",
    "\n",
    "start = perf_counter()\n",
    "raster_orig = image_preprocessing.read_gdal_with_geoinfo(trainingdata_path, offset_topleft)\n",
    "print(raster_orig['geoinfo'])\n",
    "\n",
    "dataset_full_tiles = image_preprocessing.run_tiling_dims(raster_orig['imagery'], out_shape=tile_shape, \n",
    "                                                    out_overlap=overlap, offset=offset_topleft)\n",
    "dataset_full = image_preprocessing.normalize_tiles_3d(dataset_full_tiles, nodata_vals=[0])\n",
    "dataset = tnt.dataset.TensorDataset(dataset_full['imagery'])\n",
    "end = perf_counter()\n",
    "print(f'Loading the imagery took {end - start} seconds.')\n",
    "\n",
    "print(dataset_full_tiles['imagery'].shape)\n",
    "print(dataset_full_tiles['dimensions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r'C:\\Users\\dd\\Documents\\NATUR_CUNI\\additional_projects\\prace\\ETRAINEE\\data\\test_result_3d.tif'\n",
    "\n",
    "start = perf_counter()\n",
    "arr_class = inference_utils.combine_tiles_2d(model, dataset, tile_shape, overlap, dataset_full_tiles['dimensions'])\n",
    "print(np.unique(arr_class, return_counts=True))\n",
    "inference_utils.export_result(output_path, arr_class, raster_orig['geoinfo'])\n",
    "end = perf_counter()\n",
    "print(f'The processing took {end - start} seconds.')\n",
    "plt.imshow(arr_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
